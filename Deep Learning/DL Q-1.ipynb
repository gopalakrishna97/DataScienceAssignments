{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f2b260",
   "metadata": {},
   "source": [
    "## Question 1 -\n",
    "Implement 3 different CNN architectures with a comparison table for the MNSIT\n",
    "dataset using the Tensorflow library.\n",
    "Note -\n",
    "1. The model parameters for each architecture should not be more than 8000\n",
    "parameters\n",
    "2. Code comments should be given for proper code understanding.\n",
    "3. The minimum accuracy for each accuracy should be at least 96%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84dbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Architecture 1\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 50s 26ms/step - loss: 0.1617 - accuracy: 0.9515 - val_loss: 0.0680 - val_accuracy: 0.9775\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0540 - val_accuracy: 0.9833\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0380 - accuracy: 0.9883 - val_loss: 0.0448 - val_accuracy: 0.9841\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 0.0422 - val_accuracy: 0.9855\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0430 - val_accuracy: 0.9867\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0430 - accuracy: 0.9867\n",
      "Test Accuracy: 0.9866999983787537\n",
      "Architecture 2\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1637 - accuracy: 0.9516 - val_loss: 0.0626 - val_accuracy: 0.9801\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0531 - accuracy: 0.9837 - val_loss: 0.0423 - val_accuracy: 0.9863\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.0434 - val_accuracy: 0.9875\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0306 - val_accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0318 - val_accuracy: 0.9895\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0318 - accuracy: 0.9895\n",
      "Test Accuracy: 0.9894999861717224\n",
      "Architecture 3\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 56s 29ms/step - loss: 0.3343 - accuracy: 0.8984 - val_loss: 0.1562 - val_accuracy: 0.9513\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1395 - accuracy: 0.9577 - val_loss: 0.1090 - val_accuracy: 0.9658\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1115 - accuracy: 0.9656 - val_loss: 0.1229 - val_accuracy: 0.9608\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0924 - accuracy: 0.9712 - val_loss: 0.1099 - val_accuracy: 0.9631\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0803 - accuracy: 0.9747 - val_loss: 0.0782 - val_accuracy: 0.9758\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0782 - accuracy: 0.9758\n",
      "Test Accuracy: 0.9757999777793884\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load the MNIST dataset and split it into training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the input images\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Add a channel dimension to the images (required for convolutional layers)\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Set the number of classes and input shape\n",
    "num_classes = 10\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# first CNN architecture\n",
    "def cnn_architecture_1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# second CNN architecture\n",
    "def cnn_architecture_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# third CNN architecture\n",
    "def cnn_architecture_3():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# function to Compile and train the models \n",
    "def train_model(model):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# function to Evaluate the model on the test set\n",
    "def evaluate_model(model):\n",
    "    _, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Train and evaluate the first architecture\n",
    "print(\"Architecture 1\")\n",
    "model1 = cnn_architecture_1()\n",
    "train_model(model1)\n",
    "evaluate_model(model1)\n",
    "\n",
    "# Train and evaluate the second architecture\n",
    "print(\"Architecture 2\")\n",
    "model2 = cnn_architecture_2()\n",
    "train_model(model2)\n",
    "evaluate_model(model2)\n",
    "\n",
    "# Train and evaluate the third architecture\n",
    "print(\"Architecture 3\")\n",
    "model3 = cnn_architecture_3()\n",
    "train_model(model3)\n",
    "evaluate_model(model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45c8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
